# Ética y responsabilidad en IA

## Introducción

La Inteligencia Artificial (IA) ha emergido como una fuerza transformadora en la sociedad contemporánea, prometiendo innovaciones sin precedentes en diversos campos. Sin embargo, su desarrollo y despliegue no están exentos de desafíos, especialmente en lo referente a la privacidad, la equidad y la transparencia. En este contexto, es crucial analizar cómo las directrices internacionales, las políticas de empresas líderes como Meta y la legislación nacional, como la nueva Ley Federal de Protección de Datos Personales en Posesión de Particulares (LFPDPPP, 2025) de México, convergen para fomentar un ecosistema de IA más ético y seguro.

## Los principios de IA de la OCDE: 

La Organización para la Cooperación y el Desarrollo Económicos (OCDE) ha sido pionera en establecer un marco ético para la IA. Sus principios, adoptados en 2019, buscan guiar a gobiernos, organizaciones e individuos hacia un desarrollo y uso de la IA que sea innovador y confiable, centrado en el ser humano y sus derechos. Estos principios son (OCDE, 2019):

- Crecimiento inclusivo, desarrollo sostenible y bienestar: La IA debe beneficiar a las personas y al planeta.

- Valores centrados en el ser humano y equidad: Los sistemas de IA deben diseñarse respetando el estado de derecho, los derechos humanos, los valores democráticos y la diversidad, e incluir salvaguardas para garantizar resultados justos y equitativos.

- Transparencia y explicabilidad: Debe existir transparencia y una divulgación responsable en torno a los sistemas de IA para asegurar que las personas comprendan los resultados basados en IA y puedan cuestionarlos.

- Robustez, seguridad y protección: Los sistemas de IA deben funcionar de manera robusta, segura y protegida durante todo su ciclo de vida, y los riesgos potenciales deben evaluarse y gestionarse continuamente.

- Rendición de cuentas (Accountability): Las organizaciones e individuos que desarrollan, despliegan u operan sistemas de IA deben ser responsables de su correcto funcionamiento en línea con los principios anteriores.

Estos principios sirven como una brújula moral y técnica para la comunidad internacional, influyendo en políticas y legislaciones a nivel global.

## El compromiso de Meta con la ia responsable

Meta, como uno de los principales desarrolladores y usuarios de tecnologías de IA, ha manifestado su compromiso con el desarrollo responsable de estas herramientas. A través de sus diversas plataformas y comunicaciones (Meta, s.f.-a; Meta, s.f.-b; Meta, s.f.-c; Meta, 2024), la compañía destaca varios pilares:

- Transparencia: Informar a los usuarios sobre cómo se utiliza su información para entrenar modelos de IA y cómo funcionan estos sistemas. Se busca que los usuarios comprendan las capacidades y limitaciones de la IA generativa.

- Control del usuario: Ofrecer a los usuarios opciones y controles sobre sus datos y cómo estos interactúan con las funciones de IA.

- Privacidad: Integrar la privacidad desde el diseño en el desarrollo de la IA, minimizando la recopilación de datos y aplicando técnicas de protección.

- Seguridad y protección: Desarrollar modelos de IA con múltiples capas de seguridad para prevenir usos indebidos, sesgos dañinos y la generación de contenido inapropiado. Esto incluye la evaluación de riesgos y la implementación de salvaguardas.

Equidad y no discriminación: Esforzarse por mitigar sesgos en los datos de entrenamiento y en los modelos para evitar resultados discriminatorios.

Colaboración y apertura: Compartir investigaciones y herramientas (como Llama) para fomentar la innovación responsable y permitir que la comunidad evalúe y mejore la seguridad de los modelos.

Las guías de uso responsable para modelos como Llama (Meta, s.f.-b) enfatizan la importancia de la evaluación de riesgos, la mitigación de daños y el uso ético, alineándose con los principios de la OCDE.
